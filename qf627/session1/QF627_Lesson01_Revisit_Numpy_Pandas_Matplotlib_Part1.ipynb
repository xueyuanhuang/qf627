{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QF 627 Programming and Computational Finance\n",
    "## Lesson 01 | Revisit NumPy, Pandas, & Matplotlib (feat. `bokeh` & `seaborn`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that you are sufficinetly familiar with the basics of data cleaning and analysis in pandas, we're going to take it up a notch. \n",
    "\n",
    "> Previously, the datasets were in relatively clean and straightforward formats. \n",
    "\n",
    "> However, in many cases, the data you analyze can be extremely messy and difficult to manage.\n",
    "\n",
    "> That's why we're going to practice with a more unweildy. \n",
    "\n",
    "> You'll notice that it's quite a big file – about 1.7 million rows! \n",
    "\n",
    "> These are reports from accidents in New Jersey between 2008 and 2013 from the New Jersey Department of Transportation. \n",
    "\n",
    "> The data was scraped from [PDFs of crash reports](http://www.state.nj.us/transportation/refdata/accident/) filled out by clerk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import pandas and let's load in our new and very messy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eke\\AppData\\Local\\Temp\\ipykernel_1444\\2108707814.py:1: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  accidents = pd.read_csv(\"accidents.csv\", encoding = \"ISO-8859-1\")\n"
     ]
    }
   ],
   "source": [
    "accidents = pd.read_csv(\"accidents.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents = pd.read_csv(\"accidents.csv\", \n",
    "#                         encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You may notice that you get this warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\"DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False. interactivity=interactivity, compiler=compiler, result=result)\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This dtype error happens when when a column has both strings and integer values. \n",
    "\n",
    "> You can ignore this for now because we'll fix it soon. Open up the first few rows of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case code</th>\n",
       "      <th>County Name</th>\n",
       "      <th>Municipality Name</th>\n",
       "      <th>Crash Date</th>\n",
       "      <th>Crash Day Of Week</th>\n",
       "      <th>Crash Time</th>\n",
       "      <th>Police Dept Code</th>\n",
       "      <th>Police Department</th>\n",
       "      <th>Police Station</th>\n",
       "      <th>Total Killed</th>\n",
       "      <th>...</th>\n",
       "      <th>Is Ramp</th>\n",
       "      <th>Ramp To/From Route Name</th>\n",
       "      <th>Ramp To/From Route Direction</th>\n",
       "      <th>Posted Speed</th>\n",
       "      <th>Posted Speed Cross Street</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Cell Phone In Use Flag</th>\n",
       "      <th>Other Property Damage</th>\n",
       "      <th>Reporting Badge No.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008010108-026816</td>\n",
       "      <td>ATLANTIC</td>\n",
       "      <td>ABSECON CITY</td>\n",
       "      <td>3/4/08</td>\n",
       "      <td>TU</td>\n",
       "      <td>1539</td>\n",
       "      <td>1</td>\n",
       "      <td>ATLANTIC CITY</td>\n",
       "      <td>AIU</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>50</td>\n",
       "      <td></td>\n",
       "      <td>39.41158</td>\n",
       "      <td>74.49162</td>\n",
       "      <td>N</td>\n",
       "      <td>NONE                                          ...</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008010108-163190</td>\n",
       "      <td>ATLANTIC</td>\n",
       "      <td>ABSECON CITY</td>\n",
       "      <td>12/19/08</td>\n",
       "      <td>F</td>\n",
       "      <td>1114</td>\n",
       "      <td>1</td>\n",
       "      <td>ATLANTIC CITY</td>\n",
       "      <td>TRAFFIC</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>50</td>\n",
       "      <td></td>\n",
       "      <td>39.39231</td>\n",
       "      <td>74.48952</td>\n",
       "      <td>N</td>\n",
       "      <td>NONE                                          ...</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008010108-24779</td>\n",
       "      <td>ATLANTIC</td>\n",
       "      <td>ABSECON CITY</td>\n",
       "      <td>11/25/08</td>\n",
       "      <td>TU</td>\n",
       "      <td>345</td>\n",
       "      <td>99</td>\n",
       "      <td>NJ TRANSIT P.D.</td>\n",
       "      <td>ATLANTIC CITY</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>?                                             ...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008010108-3901</td>\n",
       "      <td>ATLANTIC</td>\n",
       "      <td>ABSECON CITY</td>\n",
       "      <td>3/31/08</td>\n",
       "      <td>M</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>EAST WINDSOR</td>\n",
       "      <td>TRAFFIC UNIT</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>NONE                                          ...</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008010108-5016</td>\n",
       "      <td>ATLANTIC</td>\n",
       "      <td>ABSECON CITY</td>\n",
       "      <td>1/25/08</td>\n",
       "      <td>F</td>\n",
       "      <td>942</td>\n",
       "      <td>1</td>\n",
       "      <td>EGG HARBOR TWP</td>\n",
       "      <td>HQ</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>39.43036</td>\n",
       "      <td>74.52469</td>\n",
       "      <td>N</td>\n",
       "      <td>NONE                                          ...</td>\n",
       "      <td>1571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         case code   County Name         Municipality Name  \\\n",
       "0  2008010108-026816                ATLANTIC      ABSECON CITY               \n",
       "1  2008010108-163190                ATLANTIC      ABSECON CITY               \n",
       "2  2008010108-24779                 ATLANTIC      ABSECON CITY               \n",
       "3  2008010108-3901                  ATLANTIC      ABSECON CITY               \n",
       "4  2008010108-5016                  ATLANTIC      ABSECON CITY               \n",
       "\n",
       "   Crash Date  Crash Day Of Week  Crash Time  Police Dept Code  \\\n",
       "0      3/4/08                 TU        1539                 1   \n",
       "1    12/19/08                 F         1114                 1   \n",
       "2    11/25/08                 TU         345                99   \n",
       "3     3/31/08                 M          105                 1   \n",
       "4     1/25/08                 F          942                 1   \n",
       "\n",
       "           Police Department   Police Station   Total Killed  ...   Is Ramp  \\\n",
       "0  ATLANTIC CITY              AIU                          0  ...             \n",
       "1  ATLANTIC CITY              TRAFFIC                      0  ...             \n",
       "2  NJ TRANSIT P.D.            ATLANTIC CITY                0  ...             \n",
       "3  EAST WINDSOR               TRAFFIC UNIT                 0  ...             \n",
       "4  EGG HARBOR TWP             HQ                           0  ...             \n",
       "\n",
       "     Ramp To/From Route Name   Ramp To/From Route Direction  Posted Speed  \\\n",
       "0                                                                      50   \n",
       "1                                                                      50   \n",
       "2                                                                      10   \n",
       "3                                                                       0   \n",
       "4                                                                      50   \n",
       "\n",
       "   Posted Speed Cross Street  Latitude  Longitude  Cell Phone In Use Flag  \\\n",
       "0                             39.41158   74.49162                       N   \n",
       "1                             39.39231   74.48952                       N   \n",
       "2                         25                                            N   \n",
       "3                                                                       N   \n",
       "4                         40  39.43036   74.52469                       N   \n",
       "\n",
       "                               Other Property Damage  Reporting Badge No.  \n",
       "0  NONE                                          ...                  384  \n",
       "1  NONE                                          ...                  739  \n",
       "2  ?                                             ...                   53  \n",
       "3  NONE                                          ...                  551  \n",
       "4  NONE                                          ...                 1571  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's found out what we're working with, and get the column headers for all of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case code', ' County Name', ' Municipality Name', ' Crash Date',\n",
       "       ' Crash Day Of Week', ' Crash Time', ' Police Dept Code',\n",
       "       ' Police Department', ' Police Station', ' Total Killed',\n",
       "       ' Total Injured', ' Pedestrians Killed', ' Pedestrians Injured',\n",
       "       ' Severity', ' Intersection', ' Alcohol Involved', ' HazMat Involved',\n",
       "       ' Crash Type Code', ' Total Vehicles Involved', ' Crash Location',\n",
       "       ' Location Direction', ' Route', ' Route Suffix',\n",
       "       ' SRI (Std Rte Identifier)', ' MilePost  ', ' Road System',\n",
       "       ' Road Character', ' Road Surface Type', ' Surface Condition',\n",
       "       ' Light Condition', ' Environmental Condition', ' Road Divided By',\n",
       "       ' Temporary Traffic Control Zone', ' Distance To Cross Street',\n",
       "       ' Unit Of Measurement', ' Directn From Cross Street',\n",
       "       ' Cross Street Name', ' Is Ramp', ' Ramp To/From Route Name',\n",
       "       ' Ramp To/From Route Direction', ' Posted Speed',\n",
       "       ' Posted Speed Cross Street', ' Latitude', ' Longitude',\n",
       "       ' Cell Phone In Use Flag', ' Other Property Damage',\n",
       "       ' Reporting Badge No.'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Bummer. There's our first problem. Notice that there's a leading space in every column header. We should take it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.rename(columns = lambda x: x.strip(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents.rename(columns = lambda x: x.strip(), inplace = True) # will address empty spaces on column headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember where we renamed the columns in our dataframe previously? \n",
    "\n",
    "> This time, we're using the same rename function to do take out all of the leading spaces using `strip()`. \n",
    "\n",
    "> Pythonistas will notice that we're using the `lambda python` to apply `strip()` to every single column header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case code', 'County Name', 'Municipality Name', 'Crash Date',\n",
       "       'Crash Day Of Week', 'Crash Time', 'Police Dept Code',\n",
       "       'Police Department', 'Police Station', 'Total Killed', 'Total Injured',\n",
       "       'Pedestrians Killed', 'Pedestrians Injured', 'Severity', 'Intersection',\n",
       "       'Alcohol Involved', 'HazMat Involved', 'Crash Type Code',\n",
       "       'Total Vehicles Involved', 'Crash Location', 'Location Direction',\n",
       "       'Route', 'Route Suffix', 'SRI (Std Rte Identifier)', 'MilePost',\n",
       "       'Road System', 'Road Character', 'Road Surface Type',\n",
       "       'Surface Condition', 'Light Condition', 'Environmental Condition',\n",
       "       'Road Divided By', 'Temporary Traffic Control Zone',\n",
       "       'Distance To Cross Street', 'Unit Of Measurement',\n",
       "       'Directn From Cross Street', 'Cross Street Name', 'Is Ramp',\n",
       "       'Ramp To/From Route Name', 'Ramp To/From Route Direction',\n",
       "       'Posted Speed', 'Posted Speed Cross Street', 'Latitude', 'Longitude',\n",
       "       'Cell Phone In Use Flag', 'Other Property Damage',\n",
       "       'Reporting Badge No.'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Good job :)\n",
    "\n",
    "> Let's describe() the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Killed</th>\n",
       "      <th>Total Injured</th>\n",
       "      <th>Pedestrians Killed</th>\n",
       "      <th>Pedestrians Injured</th>\n",
       "      <th>Total Vehicles Involved</th>\n",
       "      <th>Road System</th>\n",
       "      <th>Posted Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "      <td>1.048575e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.965525e-03</td>\n",
       "      <td>3.119510e-01</td>\n",
       "      <td>4.854207e-04</td>\n",
       "      <td>1.735117e-02</td>\n",
       "      <td>1.875997e+00</td>\n",
       "      <td>5.199488e+00</td>\n",
       "      <td>3.120711e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.694568e-02</td>\n",
       "      <td>7.015340e-01</td>\n",
       "      <td>2.211335e-02</td>\n",
       "      <td>1.344480e-01</td>\n",
       "      <td>5.416507e-01</td>\n",
       "      <td>2.491480e+00</td>\n",
       "      <td>1.790289e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>4.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.200000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>9.900000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Total Killed  Total Injured  Pedestrians Killed  Pedestrians Injured  \\\n",
       "count  1.048575e+06   1.048575e+06        1.048575e+06         1.048575e+06   \n",
       "mean   1.965525e-03   3.119510e-01        4.854207e-04         1.735117e-02   \n",
       "std    4.694568e-02   7.015340e-01        2.211335e-02         1.344480e-01   \n",
       "min    0.000000e+00   0.000000e+00        0.000000e+00         0.000000e+00   \n",
       "25%    0.000000e+00   0.000000e+00        0.000000e+00         0.000000e+00   \n",
       "50%    0.000000e+00   0.000000e+00        0.000000e+00         0.000000e+00   \n",
       "75%    0.000000e+00   0.000000e+00        0.000000e+00         0.000000e+00   \n",
       "max    5.000000e+00   4.200000e+01        2.000000e+00         1.000000e+01   \n",
       "\n",
       "       Total Vehicles Involved   Road System  Posted Speed  \n",
       "count             1.048575e+06  1.048575e+06  1.048575e+06  \n",
       "mean              1.875997e+00  5.199488e+00  3.120711e+01  \n",
       "std               5.416507e-01  2.491480e+00  1.790289e+01  \n",
       "min               0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%               2.000000e+00  2.000000e+00  2.500000e+01  \n",
       "50%               2.000000e+00  5.000000e+00  2.500000e+01  \n",
       "75%               2.000000e+00  7.000000e+00  4.500000e+01  \n",
       "max               2.000000e+01  1.000000e+01  9.900000e+01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> But let's see if we could describe() a column. Let's use the describe() function for the `County Name` column header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          1048575\n",
       "unique              21\n",
       "top       MIDDLESEX   \n",
       "freq            115760\n",
       "Name: County Name, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents[\"County Name\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents[\"County Name\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So there are 21 unique values in the `County Name` column (for the 21 counties in New Jersey). \n",
    "\n",
    "> We can see that the top county with the most rows is Middlesex County with 176,402 crashes. \n",
    "\n",
    "> What are the names of the counties in New Jersey? Let's find out by using the unique() function on our `County Name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATLANTIC    ', 'BERGEN      ', 'BURLINGTON  ', 'CAMDEN      ',\n",
       "       'CAPE MAY    ', 'CUMBERLAND  ', 'ESSEX       ', 'GLOUCESTER  ',\n",
       "       'HUDSON      ', 'HUNTERDON   ', 'MERCER      ', 'MIDDLESEX   ',\n",
       "       'MONMOUTH    ', 'MORRIS      ', 'OCEAN       ', 'PASSAIC     ',\n",
       "       'SALEM       ', 'SOMERSET    ', 'SUSSEX      ', 'UNION       ',\n",
       "       'WARREN      '], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents[\"County Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents[\"County Name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looks like we're going to need to strip out the spaces out of the these county values. \n",
    "\n",
    "> This time we'll use the `map()` function which will strip the white space out of every string found in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ATLANTIC', 'BERGEN', 'BURLINGTON', 'CAMDEN', 'CAPE MAY',\n",
       "       'CUMBERLAND', 'ESSEX', 'GLOUCESTER', 'HUDSON', 'HUNTERDON',\n",
       "       'MERCER', 'MIDDLESEX', 'MONMOUTH', 'MORRIS', 'OCEAN', 'PASSAIC',\n",
       "       'SALEM', 'SOMERSET', 'SUSSEX', 'UNION', 'WARREN'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents[\"County Name\"] = accidents[\"County Name\"].map(str.strip)\n",
    "accidents[\"County Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# accidents[\"County Name\"] = accidents[\"County Name\"].map(str.strip) # will address empty spaces on each cell\n",
    "# accidents[\"County Name\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `map()` function returns a map object(which is an iterator) of the results after applying the given function to each item of a given iterable (list, tuple etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map(function, iterables)\n",
    "\n",
    "* function : It is a function to which map passes each element of given iterable.\n",
    "* iterables : It is a iterable which is to be mapped.\n",
    "\n",
    "> NOTE : You can pass one or more iterable to the map() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Returns a list of the results after applying the given function to each item of a given iterable (list, tuple etc.) \n",
    " \n",
    "> NOTE : The returned value from map() (map object) then can be passed to functions like list() (to create a list), set() (to create a set) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addition(q):\n",
    "    return q + q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "numbers = (1,2,3,4)\n",
    "result = map(addition, numbers)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def addition(q):\n",
    "#     return q + q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We double all numbers using map()\n",
    "# numbers = (1, 2, 3, 4)\n",
    "# result = map(addition, numbers)\n",
    "# print(list(result)\n",
    "#      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can also use lambda expressions with map to achieve above result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "numbers = (1,2,3,4)\n",
    "result = map(lambda x: x+x, numbers)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numbers = (1, 2, 3, 4)\n",
    "# result = map(lambda x: x + x, numbers)\n",
    "# print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 9, 11, 13]\n"
     ]
    }
   ],
   "source": [
    "list1 = [1,2,3,4]\n",
    "list2 = [6,7,8,9,10]\n",
    "result = map(lambda x, y: x+y, list1, list2)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two lists using map and lambda\n",
    "  \n",
    "# numbers1 = [1, 2, 3]\n",
    "# numbers2 = [4, 5, 6]\n",
    "  \n",
    "# result = map(lambda x, y: x + y, numbers1, numbers2)\n",
    "# print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['q', 'f'], ['6', '2', '7'], ['l', 'o', 't', 's'], ['o', 'f'], ['w', 'o', 'r', 'k']]\n"
     ]
    }
   ],
   "source": [
    "l = ['qf', '627', 'lots', 'of', 'work']\n",
    "result = map(list, l)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #List of strings\n",
    "# l = ['qf', '627', \"lovin'\", 'it']\n",
    "  \n",
    "# # map() can listify the list of strings individually\n",
    "# test = list(map(list, l))\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Good :) Speaking of strings, let's fix that dtype error we got at the beginning of the exercise. \n",
    "\n",
    "> Type in dtypes at the end of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "case code                         object\n",
       "County Name                       object\n",
       "Municipality Name                 object\n",
       "Crash Date                        object\n",
       "Crash Day Of Week                 object\n",
       "Crash Time                        object\n",
       "Police Dept Code                  object\n",
       "Police Department                 object\n",
       "Police Station                    object\n",
       "Total Killed                       int64\n",
       "Total Injured                      int64\n",
       "Pedestrians Killed                 int64\n",
       "Pedestrians Injured                int64\n",
       "Severity                          object\n",
       "Intersection                      object\n",
       "Alcohol Involved                  object\n",
       "HazMat Involved                   object\n",
       "Crash Type Code                   object\n",
       "Total Vehicles Involved            int64\n",
       "Crash Location                    object\n",
       "Location Direction                object\n",
       "Route                             object\n",
       "Route Suffix                      object\n",
       "SRI (Std Rte Identifier)          object\n",
       "MilePost                          object\n",
       "Road System                        int64\n",
       "Road Character                    object\n",
       "Road Surface Type                 object\n",
       "Surface Condition                 object\n",
       "Light Condition                   object\n",
       "Environmental Condition           object\n",
       "Road Divided By                   object\n",
       "Temporary Traffic Control Zone    object\n",
       "Distance To Cross Street          object\n",
       "Unit Of Measurement               object\n",
       "Directn From Cross Street         object\n",
       "Cross Street Name                 object\n",
       "Is Ramp                           object\n",
       "Ramp To/From Route Name           object\n",
       "Ramp To/From Route Direction      object\n",
       "Posted Speed                       int64\n",
       "Posted Speed Cross Street         object\n",
       "Latitude                          object\n",
       "Longitude                         object\n",
       "Cell Phone In Use Flag            object\n",
       "Other Property Damage             object\n",
       "Reporting Badge No.               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This shows us the type of data type object (or dtypes) the values of every column are. Objects refer to strings. `Int64` are integers. `Float64` are floats.\n",
    "\n",
    "> The `warning at the beginning` said it was column 6 that had mixed dtypes. If you look at your column list and count to the sixth column (Remember to count from zero!), you'll see that it's the `Police Dept Code` column. Let's look at every unique value in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '99', '  ', '2', '3', '4', 1, 99, 2, 3, 4], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents[\"Police Dept Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents[\"Police Dept Code\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> And there it is! As you can see, there are strings and integers mixed together in the same column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '8', '1', '6', '11', '5', '3', '13', '7', '99', '15', '14',\n",
       "       '10', '4', '12', '9', '16', '  ', '0'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents[\"Crash Type Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents[\"Crash Type Code\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Same for column 17 or the `Crash Type Code` column. \n",
    "\n",
    "> Let's fix that by changing every value in both columns to a string using the `astype()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents[\"Police Dept Code\"] = accidents[\"Police Dept Code\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents[\"Police Dept Code\"] = accidents[\"Police Dept Code\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We're changing it to a string because we don't need to do math with these numbers since they are codes so it's more beneficial to use them as objects. \n",
    "\n",
    "> If you wanted to change something to an integer or a float, you'll need to use astype(int) and astype(float) respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '99', '  ', '2', '3', '4'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents[\"Police Dept Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents[\"Police Dept Code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> That took care of that :)\n",
    "\n",
    "> Let's make our dataframe a little bit more manageable by weeding out some unnecessary columns. \n",
    "\n",
    "> Let's also create a new dataframe called `crash_info`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case code', 'County Name', 'Municipality Name', 'Crash Date',\n",
       "       'Crash Day Of Week', 'Crash Time', 'Police Dept Code',\n",
       "       'Police Department', 'Police Station', 'Total Killed', 'Total Injured',\n",
       "       'Pedestrians Killed', 'Pedestrians Injured', 'Severity', 'Intersection',\n",
       "       'Alcohol Involved', 'HazMat Involved', 'Crash Type Code',\n",
       "       'Total Vehicles Involved', 'Crash Location', 'Location Direction',\n",
       "       'Route', 'Route Suffix', 'SRI (Std Rte Identifier)', 'MilePost',\n",
       "       'Road System', 'Road Character', 'Road Surface Type',\n",
       "       'Surface Condition', 'Light Condition', 'Environmental Condition',\n",
       "       'Road Divided By', 'Temporary Traffic Control Zone',\n",
       "       'Distance To Cross Street', 'Unit Of Measurement',\n",
       "       'Directn From Cross Street', 'Cross Street Name', 'Is Ramp',\n",
       "       'Ramp To/From Route Name', 'Ramp To/From Route Direction',\n",
       "       'Posted Speed', 'Posted Speed Cross Street', 'Latitude', 'Longitude',\n",
       "       'Cell Phone In Use Flag', 'Other Property Damage',\n",
       "       'Reporting Badge No.'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_info = accidents[[\"County Name\", \"Municipality Name\", \"Crash Date\",\n",
    "               \"Crash Day Of Week\", \"Crash Time\", \"Total Killed\",\n",
    "               \"Total Injured\", \"Pedestrians Killed\", \"Pedestrians Injured\",\n",
    "               \"Total Vehicles Involved\", \"Alcohol Involved\", \"Cell Phone In Use Flag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 47 columns):\n",
      " #   Column                          Non-Null Count    Dtype \n",
      "---  ------                          --------------    ----- \n",
      " 0   case code                       1048575 non-null  object\n",
      " 1   County Name                     1048575 non-null  object\n",
      " 2   Municipality Name               1048575 non-null  object\n",
      " 3   Crash Date                      1048575 non-null  object\n",
      " 4   Crash Day Of Week               1048575 non-null  object\n",
      " 5   Crash Time                      1048575 non-null  object\n",
      " 6   Police Dept Code                1048575 non-null  object\n",
      " 7   Police Department               1048575 non-null  object\n",
      " 8   Police Station                  1048575 non-null  object\n",
      " 9   Total Killed                    1048575 non-null  int64 \n",
      " 10  Total Injured                   1048575 non-null  int64 \n",
      " 11  Pedestrians Killed              1048575 non-null  int64 \n",
      " 12  Pedestrians Injured             1048575 non-null  int64 \n",
      " 13  Severity                        1048575 non-null  object\n",
      " 14  Intersection                    1048575 non-null  object\n",
      " 15  Alcohol Involved                1048575 non-null  object\n",
      " 16  HazMat Involved                 1048575 non-null  object\n",
      " 17  Crash Type Code                 1048575 non-null  object\n",
      " 18  Total Vehicles Involved         1048575 non-null  int64 \n",
      " 19  Crash Location                  1048575 non-null  object\n",
      " 20  Location Direction              1048575 non-null  object\n",
      " 21  Route                           1048575 non-null  object\n",
      " 22  Route Suffix                    1048575 non-null  object\n",
      " 23  SRI (Std Rte Identifier)        1048575 non-null  object\n",
      " 24  MilePost                        1048575 non-null  object\n",
      " 25  Road System                     1048575 non-null  int64 \n",
      " 26  Road Character                  1048575 non-null  object\n",
      " 27  Road Surface Type               1048575 non-null  object\n",
      " 28  Surface Condition               1048575 non-null  object\n",
      " 29  Light Condition                 1048575 non-null  object\n",
      " 30  Environmental Condition         1048575 non-null  object\n",
      " 31  Road Divided By                 1048575 non-null  object\n",
      " 32  Temporary Traffic Control Zone  1048575 non-null  object\n",
      " 33  Distance To Cross Street        1048575 non-null  object\n",
      " 34  Unit Of Measurement             1048575 non-null  object\n",
      " 35  Directn From Cross Street       1048575 non-null  object\n",
      " 36  Cross Street Name               1048575 non-null  object\n",
      " 37  Is Ramp                         1048575 non-null  object\n",
      " 38  Ramp To/From Route Name         1048575 non-null  object\n",
      " 39  Ramp To/From Route Direction    1048575 non-null  object\n",
      " 40  Posted Speed                    1048575 non-null  int64 \n",
      " 41  Posted Speed Cross Street       1048575 non-null  object\n",
      " 42  Latitude                        1048575 non-null  object\n",
      " 43  Longitude                       1048575 non-null  object\n",
      " 44  Cell Phone In Use Flag          1048575 non-null  object\n",
      " 45  Other Property Damage           1048575 non-null  object\n",
      " 46  Reporting Badge No.             1048575 non-null  object\n",
      "dtypes: int64(7), object(40)\n",
      "memory usage: 376.0+ MB\n"
     ]
    }
   ],
   "source": [
    "accidents.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info = accidents[[\"County Name\", \"Municipality Name\", \"Crash Date\",\n",
    "#                \"Crash Day Of Week\", \"Crash Time\", \"Total Killed\",\n",
    "#                \"Total Injured\", \"Pedestrians Killed\", \"Pedestrians Injured\",\n",
    "#                \"Total Vehicles Involved\", \"Alcohol Involved\", \"Cell Phone In Use Flag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accidents.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many car accidents had alcohol involved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out the unique values that come up in the column `Alcohol Involved`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info[\"Alcohol Involved\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_info[\"Alcohol Involved\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have only two unique values in the column: `N` for `no` and `Y` for `yes`.\n",
    "\n",
    "> Let's find out how many incidents had Ns and how many had Ys. \n",
    "\n",
    "> We're going to use the function value_counts() on the column 'Alcohol Involved'. \n",
    "\n",
    "> We're also going to put the list in a new dataframe called `alcohol` so that it will look nicer in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol Involved</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>1017766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>30809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count\n",
       "Alcohol Involved         \n",
       "N                 1017766\n",
       "Y                   30809"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol = pd.DataFrame(accidents[\"Alcohol Involved\"].value_counts())\n",
    "alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alcohol = pd.DataFrame(accidents[\"Alcohol Involved\"].value_counts())\n",
    "# alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A lot more Ns than Ys. But just what percentage are the Ys compared to the Ns? \n",
    "\n",
    "> First, let's get the total number of crashes in our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048575"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_count = crash_info[\"Alcohol Involved\"].count()\n",
    "crash_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_count = crash_info[\"Alcohol Involved\"].count()\n",
    "# crash_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Be careful`. \n",
    "\n",
    "> The `count()` function doesn't count `NAs` or `null` values. \n",
    "\n",
    "> Always make sure to check for those using the `isnull()` function, followed by `sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crash_info[\"Alcohol Involved\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info[\"Alcohol Involved\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's create a new column named `Percent` and divide every value of the `Alcohol Involved` column by the total crashes from the `crash_count` we created above and then multiply by 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol Involved</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>1017766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>30809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count\n",
       "Alcohol Involved         \n",
       "N                 1017766\n",
       "Y                   30809"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Alcohol Involved'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mE:\\software\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Alcohol Involved'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m alcohol[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m alcohol[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlcohol Involved\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m/\u001b[39mcrash_count \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      2\u001b[0m alcohol\n",
      "File \u001b[1;32mE:\\software\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mE:\\software\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Alcohol Involved'"
     ]
    }
   ],
   "source": [
    "alcohol[\"Percentage\"] = alcohol[\"Alcohol Involved\"]/crash_count * 100\n",
    "alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alcohol[\"Percentage\"] = alcohol[\"Alcohol Involved\"]/crash_count * 100\n",
    "# alcohol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mystery solved. Only 2.9 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many total people were killed in every county?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's first use the `value_counts()` function to find out how many accidents were reported in each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_info[\"County Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info[\"County Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So let's split up every incident that happened in every county by using the `groupby()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_info.groupby(\"County Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info.groupby(\"County Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> That looks like it did nothing, but it actually DID split up the counties into their own seperate groups. \n",
    "\n",
    "> We just need to know perform an action. \n",
    "\n",
    "> If you notice, there are columns like `Total Killed`, `Total Injured`, `Pedestrians Killed`, etc. that have numbers or integers that can be summed up. \n",
    "\n",
    "> Basically, we're going to add them all up by using the `sum()` function and make it into a new dataframe called `county_crash`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_level_crash_info = crash_info.groupby(\"County Name\").sum()\n",
    "county_level_crash_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_level_crash_info = crash_info.groupby(\"County Name\").sum()\n",
    "# county_level_crash_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Well, that's grim. \n",
    "\n",
    "> Let's just take out the `Total Killed` column using `iloc` which asks what data we should slice by putting an integer based on its position. \n",
    "\n",
    "> The first value represents the rows and is separated by comma from the second value which represents the columns. \n",
    "\n",
    "> Therefore, if we want all of the rows, we put a colon. We then seperate using a comma. Then, because 'Total Killed' is the first column, we can slice it by putting in a zero. \n",
    "\n",
    "> We will also sort it by using sort_values and adding the option `ascending=False` because we want the values to descend. \n",
    "\n",
    "> Let's make it into a new dataframe called county_death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_level_total_death = crash_info.groupby(\"County Name\").sum().iloc[:, 0].sort_values(ascending = False)\n",
    "county_level_total_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_level_total_death = crash_info.groupby(\"County Name\").sum().iloc[ : , 0].sort_values(ascending = False)\n",
    "# county_level_total_death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What would be the `type` of `county_death`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(county_level_total_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_level_total_death.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(county_level_total_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_level_total_death.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make `county_death` into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(county_level_total_death)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(county_level_total_death)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about dates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You may have noticed that the dates on the 'Crash Date' are strings and not Python date objects. \n",
    "\n",
    "> This will be inconvenient because if you sort them you'll get '01/01/2008, 01/01/2009, 01/01/2010' etc. \n",
    "\n",
    "> We want them to sort by date correctly, and in order to do that, we need to turn them into the Python date format.\n",
    "\n",
    "> ***We will need to `import datetime` first.*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then we will use `apply()` along with the lambda function to turn every string in that column into the format \"%m/%d/%Y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date = pd.Series([\"3/4/08\"])\n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_info[\"Crash Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_info[\"Crash Date\"] = crash_info[\"Crash Date\"].apply(lambda x: datetime.strptime(x, \"%m/%d/%y\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info[\"Crash Date\"] = crash_info[\"Crash Date\"].apply(lambda x: datetime.strptime(x, \"%m/%d/%y\").date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we're ready to `groupby()` the `Crash Date` column every date in our dataframe and count how many accidents happened every day. \n",
    "\n",
    "> And then we will slice the first column which is how many crashes happened each day using iloc. (Colon for all rows, comma, then 0 for the first column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_info[\"Crash Date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_info[\"Crash Date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let's sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_by_date = crash_info.groupby(\"Crash Date\").count().iloc[:,0]\n",
    "crash_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_by_date.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_by_date = crash_info.groupby(\"Crash Date\").count().iloc[:,0]\n",
    "# crash_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_by_date.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like on [February 12, 2008 was a busy day for New Jersey](https://www.weather.gov/media/phi/StormReports/February12-132008.pdf) with 3,050 accidents reported to happen that day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's now save the following dataframes into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_level_total_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_level_crash_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_by_date.to_csv(\"linechart.csv\")\n",
    "county_level_total_death.to_csv(\"barchart.csv\")\n",
    "county_level_crash_info.to_csv(\"scatterplot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_level_total_death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_level_crash_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_by_date.to_csv(\"linechart.csv\")\n",
    "\n",
    "# county_level_total_death.to_csv(\"barchart.csv\")\n",
    "\n",
    "# county_level_crash_info.to_csv(\"scatterplot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_by_date_line = pd.read_csv(\"linechart.csv\")\n",
    "\n",
    "county_death_bar = pd.read_csv(\"barchart.csv\")\n",
    "\n",
    "county_crash_scatter = pd.read_csv(\"scatterplot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_by_date_line = pd.read_csv(\"linechart.csv\")\n",
    "\n",
    "# county_death_bar = pd.read_csv(\"barchart.csv\")\n",
    "\n",
    "# county_crash_scatter = pd.read_csv(\"scatterplot.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Another great feature of using python analysis in the Jupyter notebook is the ability to visualize the data using the [Bokeh visualization library](http://bokeh.pydata.org/en/latest/). \n",
    "\n",
    "> We won't go into great detail on the step-by-step process of creating beautiful graphics in your notebook, but you can see what's possible below. \n",
    "\n",
    "> You can read more documentation on Bokeh [here](http://bokeh.pydata.org/en/latest/docs/user_guide.html#userguide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's upload the datasets we'll use which we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "from bokeh.models import HoverTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bokeh.plotting import figure, show, output_file, output_notebook\n",
    "# from bokeh.models import HoverTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Bar plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's have a look at `Total Killed` in **each county**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_death_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_death_bar.sort_values(by = \"Total Killed\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_notebook()\n",
    "\n",
    "county_name = county_death_bar[\"County Name\"]\n",
    "\n",
    "bar = figure(title = \"Total Death by County\",\n",
    "            x_range = county_name,\n",
    "            plot_width = 800,\n",
    "            plot_height = 600,\n",
    "            toolbar_location = None,\n",
    "            tools = \"\")\n",
    "\n",
    "bar.vbar(x = \"County Name\",\n",
    "        top = \"Total Killed\",\n",
    "        source = county_death_bar,\n",
    "        width = 0.8)\n",
    "\n",
    "bar.xaxis.major_label_orientation = \"vertical\"\n",
    "bar.y_range.start = 0\n",
    "bar.xgrid.grid_line_color = None\n",
    "\n",
    "output_file(\"Your_First_Bokeh_Barplot.html\")\n",
    "\n",
    "show(bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_death_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_death_bar.sort_values(by = \"Total Killed\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_notebook()\n",
    "\n",
    "# county_name = county_death_bar[\"County Name\"]\n",
    "\n",
    "# bar = figure(title = \"Total Death by County\",\n",
    "#              x_range = county_name,\n",
    "#              plot_width = 800,\n",
    "#              plot_height = 600,\n",
    "#              toolbar_location = None,\n",
    "#              tools = \"\")\n",
    "\n",
    "# bar.vbar(x = \"County Name\",\n",
    "#          top = \"Total Killed\",\n",
    "#          source = county_death_bar, # this is where you input your DF\n",
    "#          width = 0.8)\n",
    "\n",
    "# bar.xaxis.major_label_orientation = \"vertical\"\n",
    "# bar.y_range.start = 0\n",
    "# bar.xgrid.grid_line_color = None\n",
    "\n",
    "# output_file(\"Your_First_Bokeh_Barplot.html\")\n",
    "\n",
    "# show(bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Scatter plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's take a look at the relationships between `Total Killed` and `Pedestrians Killed in each county`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_crash_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot = figure(title = \"The Relationships between Total Death and Pedestrians Killed in Each County\",\n",
    "                     x_axis_label = \"Total Killed\",\n",
    "                     y_axis_label = \"Pedestrians Killed\")\n",
    "\n",
    "scatterplot.circle(\"Total Killed\",\n",
    "                   \"Pedestrians Killed\",\n",
    "                   source = county_crash_scatter) # Again, this where you input your DF\n",
    "\n",
    "output_file(\"Your_First_Scatter_with_Bokeh.html\")\n",
    "\n",
    "show(scatterplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# county_crash_scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot = figure(title = \"The Relationships between Total Death and Pedestrians Killed in Each County\",\n",
    "#                      x_axis_label = \"Total Killed\",\n",
    "#                      y_axis_label = \"Pedestrians Killed\")\n",
    "\n",
    "# scatterplot.circle(\"Total Killed\",\n",
    "#                    \"Pedestrians Killed\",\n",
    "#                    source = county_crash_scatter) # Again, this where you input your DF\n",
    "\n",
    "# output_file(\"Your_First_Scatter_with_Bokeh.html\")\n",
    "\n",
    "# show(scatterplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You might want to create a `regression line` :)\n",
    "\n",
    "> As you will learn more down the line in the course, you can use library `seaborn`.  \n",
    "\n",
    "> `seaborn` is a Python data visualization library based on `matplotlib`. \n",
    "\n",
    "> It provides a high-level interface for drawing attractive and informative statistical graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lmplot(x = \"Total Killed\",\n",
    "#            y = \"Pedestrians Killed\",\n",
    "#            data = county_crash_scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.jointplot(x = \"Total Killed\",\n",
    "#               y = \"Pedestrians Killed\",\n",
    "#               data = county_crash_scatter,\n",
    "#               kind = \"reg\",\n",
    "#               joint_kws = {\"color\":\"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Line Chart`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's see the number of New Jersey car crashes over time (2008-2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_by_date_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crash_by_date_line[\"Crash Date\"] = pd.to_datetime(crash_by_date_line[\"Crash Date\"])\n",
    "# crash_by_date_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = figure(title = \"The Number of New Jersey Car Crashes Over Time (2008-2013)\",\n",
    "#               x_axis_type = \"datetime\",\n",
    "#               plot_width = 800,\n",
    "#               plot_height = 600)\n",
    "\n",
    "# line.line(crash_by_date_line[\"Crash Date\"],\n",
    "#           crash_by_date_line[\"County Name\"],\n",
    "#           line_width = 1,\n",
    "#           line_color = \"purple\")\n",
    "\n",
    "# line.yaxis.axis_label = \"County Name\"\n",
    "# line.xaxis.axis_label = \"Crash Date\"\n",
    "# line.xaxis.major_label_orientation = \"vertical\"\n",
    "\n",
    "# output_file(\"line_timeseries.html\")\n",
    "# show(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Thank you for working with the script :)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
